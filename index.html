<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="video turing test@ICCV19">
    <meta name="author" content="yjheo@bi.snu.ac.kr">
    <link rel="icon" href="./data/VIC.png">

    <title>VTT: Toward Human level Video Story Understanding</title>

    <link href="./data/bootstrap.min.css" rel="stylesheet">
    <link href="./data/carousel.css" rel="stylesheet">
  </head>

  
  <body>
    <div class="navbar-wrapper">
      <div class="container">

        <nav class="navbar navbar-default navbar-fixed-top">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              <a class="navbar-brand" href="videoturingtest.github.io/index.html">ICCV19-VTT</a>
            </div>
            <div id="navbar" class="navbar-collapse collapse">
              <ul class="nav navbar-nav">
                <li class="active"><a href="https://videoturingtest.github.io">Home</a></li>
                <li><a href="https://videoturingtest.github.io/#cfp">Call for Papers</a></li>
				<li><a href="https://videoturingtest.github.io/#dates">Important dates</a></li>
				<li><a href="https://videoturingtest.github.io/#scehdules">Schedules</a></li>
				<li><a href="https://videoturingtest.github.io/#invited">Invited Speakers</a></li>
				<li><a href="https://videoturingtest.github.io/#organizers">Organizers</a></li>
              </ul>
            </div>
          </div>
        </nav>

      </div>
    </div>


    <div id="myCarousel" class="carousel slide" data-ride="carousel">
      <ol class="carousel-indicators">
        <li data-target="#myCarousel" data-slide-to="0" class="active"></li>
      </ol>
      <div class="carousel-inner" role="listbox">
        <div class="item active">
          <img class="first-slide" src="./data/main.png" alt="First slide">
          <div class="container">
            <div class="carousel-caption">
              <h1><b>Video Turing Test</b>:<br> Toward Human level Video Story Understanding</h1>
              <p>@ ICCV 2019, Nov 2, 2019, Seoul, Korea</p>
              <p>
				<a class="btn btn-default" href="http://iccv2019.thecvf.com/">
					<img src="./data/ICCV19logo_main.png" width="120" />
				</a>
			  </p>
            </div>
          </div>
        </div>
      </div>
    </div>


    <div class="container marketing">
      <div class="row featurette">
		  <div class="col-md-12" id="cfp">
			  <h1> Call for Papers </h1>
			  The ability to craft and understand stories is a crucial cognitive tool used by humans for communication. According to computational linguists, narrative theorists and cognitive scientists, the story understanding is a good proxy to measure the readers' intelligence. Readers can understand a story as a way of problem-solving in which, for example, they keep focusing on how main characters overcome certain obstacles throughout the story. Readers need to make inferences both in prospect and in retrospect about the causal relationships between different events in the story. Especially, the video story data such as TV shows and movies can serve as an excellent testbed to evaluate the human-level AI algorithms from two points of view. First, video data have different modalities such as a sequence of images, audios (including dialogue, sound effects and background music) and  text (subtitles or added comments). Second, video data show various cross-sections of everyday life. Therefore, understanding video story can be thought of a significant challenge to current AI technology, which involves analyzing and simulating human vision, language, thinking, and behavior.  Recent research has shown that story plays a vital role in many AI tasks: obtaining natural language descriptions from images and videos, question and answering about visual content, intuitive exploration of large collections of geotagged or timestamped images, summarization of hours-long egocentric videos and boosting the accuracy of face, activity, and object recognition in unstructured images or videos. These applications, however, only scratch the surface of what may be possible with such semantically rich understanding of story. This workshop aims to invite experts in a variety of related fields, including vision, graphics, language processing, multimedia, and speech/sound recognition, to provide a perspective on the research that exists, and initiates discussion of future challenges in data-driven video understanding.
			  <br><br>
			  <ul>
				  <li>Deep learning architecture for multi-modal video story representation</li>
				  <li>Question answering about video story</li>
				  <li>Summarization and retrieval from long story video contents</li>
				  <li>Scene description generation for video understanding</li>
				  <li>Scene graph generation and relationship detection from video</li>
				  <li>Activity/Event recognition from video</li>
				  <li>Character identification & interaction modeling in video</li>
				  <li>Emotion recognition in video</li>
				  <li>Novel tasks about video understanding and challenge dataset</li>
			</ul>

		  This workshop will invite a selected set of leading researchers in the related fields for invited talks. Also, we encourage <b>submissions of papers as extended abstract within 4 pages</b>, excluding references or supplementary materials. All submissions must be in pdf format as a single file (incl. supplementary materials) using ICCV formats and submitted through CMT[TODO:CMT link]. Note that this workshop has not published proceedings, and thus the accepted submission will not be counted as a publication. All accepted papers will be presented as posters during the workshop and listed on the website. Additionally, a small number of accepted papers will be selected to be presented as contributed talks.

		  </div>
		</div>	
		<br>
		
		<div class="row featurette" id="dates">
			<h2> Important Dates </h2>
			<table class="table table-striped">
			  <tbody>
				<tr>	
				  <th scope="row">Paper Submission Deadline</th>
				  <td>August 30, 2019</td>
				</tr>
				<tr>	
				  <th scope="row">Notification to Authors</th>
				  <td>September 26, 2019</td>
				</tr>
				<tr>	
				  <th scope="row">Paper Camera-Ready version Deadline</th>
				  <td>October 18, 2019</td>
				</tr>
				<tr>	
				  <th scope="row">Workshop date</th>
				  <td>November 2, 2019</td>
				</tr>
			  </tbody>
			</table>
		<div>


	<div class="col-md-12" id="schedules">
		<div class="row featurette">
			<h2> Schedules </h2>
			<table class="table table-striped">
			  <thead>
				<tr>
				  <th scope="col">Time</th>
				  <th scope="col">Content</th>
				  <th scope="col">Presenter</th>
				</tr>
			  </thead>
			  <tbody>
				<tr>	
				  <th scope="row">14:00 - 14:15</th>
				  <td>Welcome & Opening talk</td>
				  <td>Organizer</td>
				</tr>
				<tr>
				  <th scope="row">14:15 - 14:45</th>
				  <td>Invited Talk 1</td>
				  <td>Speaker</td>
				</tr>
				<tr>
				  <th scope="row">14:45 - 15:15</th>
				  <td>Spotlight Talks (6 papers)</td>
				  <td>Speaker</td>
				</tr>
				<tr>
				  <th scope="row">15:15 - 15:45</th>
				  <td>Invited Talk 2</td>
				  <td>Speaker</td>
				</tr>
				<tr>
				  <th scope="row">15:40 - 16:55</th>
				  <td>Coffee Break & Poster session</td>
				  <td>Speaker</td>
				</tr>
				<tr>
				  <th scope="row">16:55 - 17:25</th>
				  <td>Invited Talk 3</td>
				  <td>Speaker</td>
				</tr>
				<tr>
				  <th scope="row">17:25 - 17:40</th>
				  <td>Contributed Talk 1 </td>
				  <td>Speaker</td>
				</tr>
				<tr>
				  <th scope="row">17:40 - 17:55</th>
				  <td>Contributed Talk 2</td>
				  <td>Speaker</td>
				</tr>
				<tr>
				  <th scope="row">17:20 - 17:55</th>
				  <td>Invited Talk 8</td>
				  <td>Speaker</td>
				</tr>
				<tr>
				  <th scope="row">17:55 - 18:00</th>
				  <td>Closing</td>
				  <td>Organizer</td>
				</tr>
			  </tbody>
			</table>
		<div>
	</div>

		<br>
	<div class="col-md-12" id="invited">
		<div class="row featurette">
		<h2> Invited Speakers </h2>
			<div class="col-md-2">
			  <img class="featurette-image img-responsive center-block" data-src="holder.js/200x200/auto" alt="200x200" src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiIHN0YW5kYWxvbmU9InllcyI/PjxzdmcgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB3aWR0aD0iNTAwIiBoZWlnaHQ9IjUwMCIgdmlld0JveD0iMCAwIDUwMCA1MDAiIHByZXNlcnZlQXNwZWN0UmF0aW89Im5vbmUiPjxkZWZzLz48cmVjdCB3aWR0aD0iNTAwIiBoZWlnaHQ9IjUwMCIgZmlsbD0iI0VFRUVFRSIvPjxnPjx0ZXh0IHg9IjE5MC4zMTI1IiB5PSIyNTAiIHN0eWxlPSJmaWxsOiNBQUFBQUE7Zm9udC13ZWlnaHQ6Ym9sZDtmb250LWZhbWlseTpBcmlhbCwgSGVsdmV0aWNhLCBPcGVuIFNhbnMsIHNhbnMtc2VyaWYsIG1vbm9zcGFjZTtmb250LXNpemU6MjNwdDtkb21pbmFudC1iYXNlbGluZTpjZW50cmFsIj41MDB4NTAwPC90ZXh0PjwvZz48L3N2Zz4=" data-holder-rendered="true">
			</div>
			<div class="col-md-10"> 
			<p class="lead">Byoung-Tak, Zhang, Seoul National University</p>
			How does the biological mind work? How does the brain build a model of the world to instantly and robustly act on it? What kinds of processing and organizational mechanisms allow the brain to learn so rapidly, flexibly, and continuously in a noisy, dynamic, and changing environment? How can we build smart machines that perceive, think, act, and learn like the human brain and mind? In the Biointelligence Lab and the Cognitive Robotics and ArtificialIntelligence Center (CRAIC) we pursue these questions using diverse methods of cognitive modeling, computational neuroscience, robotics, and computer science.
			</div>
		</div>
		<br><br>
		<div class="row featurette">
			<div class="col-md-2">
			  <img class="featurette-image img-responsive center-block" data-src="holder.js/200x200/auto" alt="200x200" src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiIHN0YW5kYWxvbmU9InllcyI/PjxzdmcgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB3aWR0aD0iNTAwIiBoZWlnaHQ9IjUwMCIgdmlld0JveD0iMCAwIDUwMCA1MDAiIHByZXNlcnZlQXNwZWN0UmF0aW89Im5vbmUiPjxkZWZzLz48cmVjdCB3aWR0aD0iNTAwIiBoZWlnaHQ9IjUwMCIgZmlsbD0iI0VFRUVFRSIvPjxnPjx0ZXh0IHg9IjE5MC4zMTI1IiB5PSIyNTAiIHN0eWxlPSJmaWxsOiNBQUFBQUE7Zm9udC13ZWlnaHQ6Ym9sZDtmb250LWZhbWlseTpBcmlhbCwgSGVsdmV0aWNhLCBPcGVuIFNhbnMsIHNhbnMtc2VyaWYsIG1vbm9zcGFjZTtmb250LXNpemU6MjNwdDtkb21pbmFudC1iYXNlbGluZTpjZW50cmFsIj41MDB4NTAwPC90ZXh0PjwvZz48L3N2Zz4=" data-holder-rendered="true">
			</div>
			<div class="col-md-10">
			<p class="lead">Name, Affiliation</p>
			Bio and Abs.
			</div>
		</div>
		<br><br>
		<div class="row featurette">
			<div class="col-md-2">
			  <img class="featurette-image img-responsive center-block" data-src="holder.js/200x200/auto" alt="200x200" src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiIHN0YW5kYWxvbmU9InllcyI/PjxzdmcgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB3aWR0aD0iNTAwIiBoZWlnaHQ9IjUwMCIgdmlld0JveD0iMCAwIDUwMCA1MDAiIHByZXNlcnZlQXNwZWN0UmF0aW89Im5vbmUiPjxkZWZzLz48cmVjdCB3aWR0aD0iNTAwIiBoZWlnaHQ9IjUwMCIgZmlsbD0iI0VFRUVFRSIvPjxnPjx0ZXh0IHg9IjE5MC4zMTI1IiB5PSIyNTAiIHN0eWxlPSJmaWxsOiNBQUFBQUE7Zm9udC13ZWlnaHQ6Ym9sZDtmb250LWZhbWlseTpBcmlhbCwgSGVsdmV0aWNhLCBPcGVuIFNhbnMsIHNhbnMtc2VyaWYsIG1vbm9zcGFjZTtmb250LXNpemU6MjNwdDtkb21pbmFudC1iYXNlbGluZTpjZW50cmFsIj41MDB4NTAwPC90ZXh0PjwvZz48L3N2Zz4=" data-holder-rendered="true">
			</div>
			<div class="col-md-10">
			<p class="lead">Name, Affiliation</p>
			Bio and Abs.
			</div>
		</div>
      </div>

      <hr class="featurette-divider">

      <div class="row featurette">
	  <div class="col-md-12" id="organizers">
	  <h2> Organizers </h2>
        <div class="col-lg-4">
          <img class="img-circle" src="data:image/gif;base64,R0lGODlhAQABAIAAAHd3dwAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==" alt="Generic placeholder image" width="140" height="140">
          <h5>Seongho Choi, Seoul National University</h5>
        </div>
        <div class="col-lg-4">
          <img class="img-circle" src="data:image/gif;base64,R0lGODlhAQABAIAAAHd3dwAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==" alt="Generic placeholder image" width="140" height="140">
          <h5>Kyoung-Woon On, Seoul National University</h5>
        </div>
		<div class="col-lg-4">
          <img class="img-circle" src="data:image/gif;base64,R0lGODlhAQABAIAAAHd3dwAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==" alt="Generic placeholder image" width="140" height="140">
          <h5>Yu-Jung Heo, Seoul National University</h5>
        </div>
		<div class="col-lg-4">
          <img class="img-circle" src="data:image/gif;base64,R0lGODlhAQABAIAAAHd3dwAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==" alt="Generic placeholder image" width="140" height="140">
          <h5>Haeyong Kang, KAIST</h5>
        </div>
		<div class="col-lg-4">
          <img class="img-circle" src="data:image/gif;base64,R0lGODlhAQABAIAAAHd3dwAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==" alt="Generic placeholder image" width="140" height="140">
          <h5>Krishna Mohan, Indian Institute of Technology Hyderabad</h5>
        </div>
		<div class="col-lg-4">
          <img class="img-circle" src="data:image/gif;base64,R0lGODlhAQABAIAAAHd3dwAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==" alt="Generic placeholder image" width="140" height="140">
          <h5>Ting Han, National Institue of Advanced Industrial Science and Technology</h5>
        </div>
		<div class="col-lg-4">
          <img class="img-circle" src="data:image/gif;base64,R0lGODlhAQABAIAAAHd3dwAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==" alt="Generic placeholder image" width="140" height="140">
          <h5>Chang Dong Yoo, KAIST</h5>
        </div>
		<div class="col-lg-4">
          <img class="img-circle" src="data:image/gif;base64,R0lGODlhAQABAIAAAHd3dwAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==" alt="Generic placeholder image" width="140" height="140">
          <h5>Gunhee Kim, Seoul National University</h5>
        </div>
		<div class="col-lg-4">
          <img class="img-circle" src="data:image/gif;base64,R0lGODlhAQABAIAAAHd3dwAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==" alt="Generic placeholder image" width="140" height="140">
          <h5>Byoung-Tak Zhang, Seoul National University</h5>
        </div>
	</div>	

	<hr class="featurette-divider">
	<div class="col-md-12" id="organizers">

		<h2> Program Committee </h2>
		<ul>
				  <li>Seon Joo Kim (Yonsei University)</li>
				  <li>Ji-Hwan Kim (Sogang University)</li>
				  <li>Seong-Bae Park (Kyung Hee University)</li>
				  <li>Byung-Chull Bae (Hongik University)</li>
				  <li>Junmo Kim (KAIST)</li>
				  <li>In So Kweon (KAIST)</li>
				  <li>Bohyung Han (Seoul National University)</li>
				  <li>Junseok Kwon (Chung-Ang University)</li>
				  <li>Eun-Sol Kim (Kakao Brain)</li>
				  <li>Jung-Woo Ha (Naver)</li>
				  <li>Kyung-Min Kim (Naver)</li>
				  <li>Jin-Hwa Kim (SK Telecom)</li>

			</ul>
  </div>


	  <hr class="featurette-divider">
	  <div class="col-md-12" id="sponsors">
	  <h2> Sponsors </h2>
	  </div>
        <div class="col-lg-4">
          <img class="featurette-image img-responsive center-block" src="data:image/gif;base64,R0lGODlhAQABAIAAAHd3dwAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==" alt="Generic placeholder image" width="140" height="140">
        </div>
        <div class="col-lg-4">
          <img class="featurette-image img-responsive center-block" src="data:image/gif;base64,R0lGODlhAQABAIAAAHd3dwAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==" alt="Generic placeholder image" width="140" height="140">
        </div>
		<div class="col-lg-4">
          <img class="featurette-image img-responsive center-block" src="data:image/gif;base64,R0lGODlhAQABAIAAAHd3dwAAACH5BAAAAAAALAAAAAABAAEAAAICRAEAOw==" alt="Generic placeholder image" width="140" height="140">
        </div>
      </div>

	  <hr class="featurette-divider">
      <footer>
        <p class="pull-right"><a href="videoturingtest.github.io/index.html">Back to top</a></p>
        <p>© 2019 Video Intelligence Center @ Seoul National University </p>
      </footer>

    </div>


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="./data/jquery.min.js.다운로드"></script>
    <script src="./data/bootstrap.min.js.다운로드"></script>
    <!-- Just to make our placeholder images work. Don't actually copy the next line! -->
    <script src="./data/holder.js.다운로드"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="./data/ie10-viewport-bug-workaround.js.다운로드"></script>


<svg xmlns="http://www.w3.org/2000/svg" width="500" height="500" viewBox="0 0 500 500" preserveAspectRatio="none" style="visibility: hidden; position: absolute; top: -100%; left: -100%;"><defs></defs><text x="0" y="23" style="font-weight:bold;font-size:23pt;font-family:Arial, Helvetica, Open Sans, sans-serif;dominant-baseline:middle">500x500</text></svg></body></html>
